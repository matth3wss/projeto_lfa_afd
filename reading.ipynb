{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import OrderedDict as od\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reserved_words_and_counts(csv_df):\n",
    "    \"\"\"\n",
    "    Analyzes a DataFrame containing strings and extracts reserved words, along with their character counts.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_df (pandas.DataFrame): The DataFrame containing strings to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries, each containing information about a reserved word, including the word itself\n",
    "          and its character count. The dictionary format is as follows:\n",
    "          [\n",
    "            {\"word\": str, \"size\": int},\n",
    "            {\"word\": str, \"size\": int},\n",
    "            ...\n",
    "          ]\n",
    "\n",
    "    Note:\n",
    "    - Reserved words are identified as lowercase strings excluding the '<' character.\n",
    "    - The function calculates the size (character count) of each reserved word.\n",
    "    - The returned list contains dictionaries with information about each reserved word and its size.\n",
    "    \"\"\"\n",
    "    reserved_words = [row for row in csv_df.values for char in row if char.islower() and char != \"<\"]         \n",
    "    size = [len(c) for word in reserved_words for c in word]\n",
    "    \n",
    "    json_data = []\n",
    "    for word, size in zip(reserved_words, size):\n",
    "        json = {\n",
    "            \"word\": word,\n",
    "            \"size\": size\n",
    "        }\n",
    "        json_data.append(json)\n",
    "    \n",
    "    return json_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_terminals(csv_df):\n",
    "    \"\"\"\n",
    "    Extracts terminal letters from reserved words obtained by analyzing a DataFrame containing strings.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_df (pandas.DataFrame): The DataFrame containing strings to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of individual terminal letters obtained from the reserved words.\n",
    "\n",
    "    Note:\n",
    "    - This function relies on the 'reserved_words_and_counts' function to identify reserved words and their counts.\n",
    "    - The function extracts individual letters from the reserved words to create a list of terminal letters.\n",
    "    \"\"\"\n",
    "    reserved_words = [row[\"word\"] for row in reserved_words_and_counts(csv_df)]\n",
    "    \n",
    "    terminal_letters = [c for word in reserved_words for char in word for c in char]\n",
    "    return terminal_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_terminal_letters(csv_df):\n",
    "    \"\"\"\n",
    "    Extracts unique terminal letters from a DataFrame containing strings.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_df (pandas.DataFrame): The DataFrame containing strings to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of unique terminal letters found in the strings.\n",
    "\n",
    "    Note:\n",
    "    - The function ignores uppercase letters, 'ε' (epsilon), and non-letter characters.\n",
    "    - Uses the 'collections.OrderedDict' to preserve the order of unique terminal letters.\n",
    "    \"\"\"\n",
    "    terminal_letters = list(od.fromkeys((c for row in csv_df.values for char in row for c in char if c.islower() and c != 'ε')))\n",
    "    return terminal_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_afnd_skeleton(csv_df):\n",
    "    \"\"\"\n",
    "    Creates the skeleton of an AFND (Nondeterministic Finite Automaton) represented as a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_df (pandas.DataFrame): The DataFrame containing strings to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The AFND skeleton represented as a DataFrame with appropriate column headers.\n",
    "\n",
    "    Note:\n",
    "    - The DataFrame includes columns for the alphabet ('sigma') and terminal letters.\n",
    "    - Rows represent states in the AFND.\n",
    "    - The first row is the start state ('S'), and subsequent rows represent states labeled with uppercase letters.\n",
    "    - Empty cells indicate transitions that are not defined.\n",
    "    \"\"\"\n",
    "    terminal_letters = unique_terminal_letters(csv_df)\n",
    "    afnd_skeleton_df = pd.DataFrame(columns=['sigma'] + [str(c) for c in terminal_letters])\n",
    "    afnd_skeleton_df.at[0, 'sigma'] = 'S'\n",
    "    \n",
    "    alphabet = list(string.ascii_uppercase)\n",
    "    size = len(extract_terminals(csv_df))\n",
    "    \n",
    "    symbols = [symbol for letters in alphabet[:size] for symbol in letters]\n",
    "    for i, symbol in enumerate(symbols):\n",
    "        afnd_skeleton_df.at[i+1, \"sigma\"] = symbol\n",
    "    \n",
    "    afnd_skeleton_df = afnd_skeleton_df.fillna('')\n",
    "    \n",
    "    return afnd_skeleton_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_variables_df(csv_df):\n",
    "    \n",
    "    symbol_pattern = r'<[A-Z]> ::='\n",
    "    variable_pattern = r'([a-z])<([A-Z])>'\n",
    "    \n",
    "    lines = [str(row) for row in csv_df.values if re.search(symbol_pattern, str(row)) for char in row]\n",
    "    \n",
    "    rg = []\n",
    "    \n",
    "    for line in lines:       \n",
    "        symbol = [match[1] for match in re.findall(symbol_pattern, line) if re.search(variable_pattern, line)]\n",
    "        terminals = [match[0] for match in re.findall(variable_pattern, line)]\n",
    "        variables = [match[1] for match in re.findall(variable_pattern, line)]\n",
    "        \n",
    "        json = {\n",
    "            \"symbol\": symbol,\n",
    "            \"terminals\": terminals,\n",
    "            \"variables\": variables\n",
    "        }\n",
    "        rg.append(json)\n",
    "    return rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_variables_list(words):\n",
    "    \n",
    "    variable_pattern = r'([a-z])<([A-Z])>'\n",
    "    \n",
    "    symbols = [re.sub(r'[^a-zA-Z]', '', words[i - 1]) for i, value in enumerate(words) if value == '::=']\n",
    "    \n",
    "    result_lists = []\n",
    "    current_list = []\n",
    "    collect_values = False\n",
    "\n",
    "    # Iterate through the input list\n",
    "    for item in words:\n",
    "        # Check if \"[\" is found, and stop collecting values if so\n",
    "        if \"[\" in item:\n",
    "            if current_list:\n",
    "                result_lists.append(current_list)\n",
    "                current_list = []\n",
    "            collect_values = False\n",
    "        # If collect_values is True and the item is not at index 0 or 1, remove \"[\" and \"]\" and add the item to the current_list\n",
    "        if collect_values and words.index(item) not in [0, 1]:\n",
    "            item = item.strip(\"[]\")\n",
    "            current_list.append(item)\n",
    "        # Check if item is at index 1, and start collecting values if so\n",
    "        if item == \"::=\":\n",
    "            collect_values = True\n",
    "\n",
    "    # Append the last current_list if it is not empty\n",
    "    if current_list:\n",
    "        result_lists.append(current_list)\n",
    "\n",
    "    rg = []\n",
    "    \n",
    "    for i, symbol in enumerate(symbols):\n",
    "        terminals = []\n",
    "        variables = []\n",
    "        for j, word in enumerate(result_lists[i]):\n",
    "            if re.search(variable_pattern, word) is None:\n",
    "                continue\n",
    "            terminals.append([match[0] for match in re.findall(variable_pattern, word) if re.search(variable_pattern, word) is not None])\n",
    "            variables.append([match[1] for match in re.findall(variable_pattern, word) if re.search(variable_pattern, word) is not None])\n",
    "            (variables)\n",
    "            \n",
    "        json = {\n",
    "            \"symbol\": symbol,\n",
    "            \"terminals\": terminals,\n",
    "            \"variables\": variables\n",
    "        }\n",
    "        rg.append(json)   \n",
    "    return rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_variables(afnd_df, csv_df, last_state):\n",
    "    import re\n",
    "    \n",
    "    alphabet = list(string.ascii_uppercase)\n",
    "    variable_pattern = r'([a-z])<([A-Z])>'\n",
    "    symbol_pattern = r'<[A-Z]>'\n",
    "    \n",
    "    \n",
    "    old_variables = list(od.fromkeys(variable for line in extract_variables_df(csv_df) for variable in line[\"variables\"]))\n",
    "    new_states_count = len(old_variables)\n",
    "    index_last_state = alphabet.index(last_state) + 1\n",
    "    total = new_states_count + index_last_state\n",
    "    symbols = [symbol for letters in alphabet[index_last_state:total] for symbol in letters]\n",
    "\n",
    "    # Update the \"sigma\" column in afnd_df starting from the end\n",
    "    for i, symbol in enumerate(symbols, start=index_last_state):\n",
    "        afnd_df.at[i+1, \"sigma\"] = symbol\n",
    "\n",
    "    lines = [str(row) for row in csv_df.values if re.search(variable_pattern, str(row)) for char in row]\n",
    "    words_original = [word for sentence in lines for word in sentence.split()]\n",
    "    words = words_original.copy()\n",
    "\n",
    "    new_variables = []\n",
    "\n",
    "    for i in range(new_states_count):\n",
    "        for j, word in enumerate(words):\n",
    "            match = re.search(variable_pattern, word)\n",
    "             \n",
    "            if match is None:\n",
    "                continue\n",
    "                \n",
    "            if match.group(2) == old_variables[i]:\n",
    "                words[j] = f\"{match[1]}<{symbols[i]}>\"\n",
    "                json_data = {\n",
    "                    \"old_variable\": old_variables[i],\n",
    "                    \"new_variable\": symbols[i]\n",
    "                }\n",
    "                new_variables.append(json_data)\n",
    "    \n",
    "    \n",
    "    def generate_same_structure(original_structure, new_structure):\n",
    "        result_structure = []\n",
    "\n",
    "        for orig, new in zip(original_structure, new_structure):\n",
    "            if isinstance(orig, list):\n",
    "                result_structure.append(generate_same_structure(orig, new))\n",
    "            else:\n",
    "                # Preserve the original square brackets\n",
    "                result_structure.append(orig[0] + new[1:-1] + orig[-1])\n",
    "\n",
    "        return result_structure\n",
    "    \n",
    "    words = generate_same_structure(words_original, words)\n",
    "    words = [word.replace('||', '|') for word in words]\n",
    "    for data in new_variables:\n",
    "        words = [word.replace(f'<{data[\"old_variable\"]}>', f'<{data[\"new_variable\"]}>') for word in words]\n",
    "                \n",
    "    new_variables = [dict(t) for t in {tuple(d.items()) for d in new_variables}]\n",
    "    new_variables = sorted(new_variables, key=lambda k: k['new_variable'])\n",
    "    \n",
    "    afnd_df = afnd_df.fillna('')\n",
    "    \n",
    "    return afnd_df, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_afnd(csv_df):\n",
    "    \"\"\"\n",
    "    Create an afnd from a dataframe\n",
    "    return: afnd\n",
    "    \"\"\"\n",
    "    \n",
    "    afnd_df = create_afnd_skeleton(csv_df) \n",
    "    \n",
    "    reserved_counts = reserved_words_and_counts(csv_df)  \n",
    "    alphabet = list(string.ascii_uppercase)\n",
    "    last_state = 'S'\n",
    "    final_state = []\n",
    "    flag = False\n",
    "    \n",
    "    for row in reserved_counts: \n",
    "        \n",
    "        initial_state = 'S'\n",
    "        \n",
    "        word = [c for char in row[\"word\"] for c in char]\n",
    "        \n",
    "        for index, char in enumerate(word): \n",
    "            if not final_state: # Se estiver vazio\n",
    "                if not flag: \n",
    "                    afnd_df.loc[afnd_df['sigma'] == initial_state, char] = alphabet[index]\n",
    "                    last_state = alphabet[index] \n",
    "                    flag = True\n",
    "                    continue \n",
    "                  \n",
    "                if flag and last_state == alphabet[0]:\n",
    "                    afnd_df.loc[afnd_df['sigma'] == last_state, char] = alphabet[1]   \n",
    "                    last_state = alphabet[1]           \n",
    "            else:      \n",
    "                if last_state[-1] in (final_state):\n",
    "                    if not afnd_df.loc[afnd_df['sigma'] == last_state, char].isna().all():\n",
    "                        afnd_df.loc[afnd_df['sigma'] == initial_state, char] += f\"{',' if afnd_df.loc[afnd_df['sigma'] == initial_state, char].any() else ''}{alphabet[alphabet.index(last_state) + 1]}\"\n",
    "                        last_state = alphabet[((alphabet.index(last_state) + 1))]\n",
    "                    continue\n",
    "                \n",
    "                afnd_df.loc[afnd_df['sigma'] == last_state, char] = alphabet[((alphabet.index(last_state) + 1))]   \n",
    "                last_state = alphabet[((alphabet.index(last_state) + 1))] \n",
    "                      \n",
    "        final_state.append(last_state)\n",
    "    afnd_df, words = replace_variables(afnd_df, csv_df, last_state)\n",
    "    new_variables = extract_variables_list(words)\n",
    "    return afnd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sigma</th>\n",
       "      <th>s</th>\n",
       "      <th>e</th>\n",
       "      <th>n</th>\n",
       "      <th>t</th>\n",
       "      <th>a</th>\n",
       "      <th>o</th>\n",
       "      <th>i</th>\n",
       "      <th>u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>[AH]</td>\n",
       "      <td>[CM]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>E</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>G</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>H</td>\n",
       "      <td></td>\n",
       "      <td>I</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>J</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>K</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>K</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>L</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>L</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Q</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Q</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[AH]</td>\n",
       "      <td></td>\n",
       "      <td>BI</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[CM]</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sigma     s     e  n  t  a  o i u\n",
       "0      S  [AH]  [CM]                \n",
       "1      A           B                \n",
       "2      B                            \n",
       "3      C              D             \n",
       "4      D                 E          \n",
       "5      E                    F       \n",
       "6      F                       G    \n",
       "7      G                            \n",
       "8      H           I                \n",
       "9      I              J             \n",
       "10     J                    K       \n",
       "11     K                       L    \n",
       "12     L                            \n",
       "13     M     N                      \n",
       "14     N                 O          \n",
       "15     O                    P       \n",
       "16     P                       Q    \n",
       "17     Q                            \n",
       "18  [AH]          BI                \n",
       "19  [CM]     N        D             "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def determinize_afnd(afnd_df):\n",
    "    afd_df = afnd_df.copy() # Cria uma cópia do DataFrame de AFND\n",
    "    states_to_process = [0] # Inicializa a lista de estados a serem processados\n",
    "    processed_states = set() # Conjunto para manter controle dos estados já processados\n",
    "    indeterminisms = {}\n",
    "    \n",
    "    while states_to_process: # Processa os estados até que a lista esteja vazia\n",
    "        # Pega o próximo estado a ser processado\n",
    "        current_state_idx = states_to_process.pop(0)\n",
    "        current_state = afd_df.iloc[current_state_idx, 0]\n",
    "\n",
    "        if current_state in processed_states: # Verifica se o estado já foi processado\n",
    "            continue\n",
    "\n",
    "        processed_states.add(current_state) # Adiciona o estado atual ao conjunto de estados processados\n",
    "\n",
    "        for symbol in afd_df.columns[1:]: # Itera sobre os símbolos do alfabeto (terminais)\n",
    "            if symbol != 'sigma':\n",
    "                combined_transitions = []\n",
    "\n",
    "                for state in current_state.split(','):\n",
    "                    transitions = afnd_df.loc[afnd_df['sigma'] == state, symbol].values[0]\n",
    "                    combined_transitions.extend(transitions.split(',') if pd.notna(transitions) else [])\n",
    "\n",
    "                if len(combined_transitions) > 1:\n",
    "                    combined_transitions = sorted(combined_transitions)\n",
    "                    new_value = f\"[{''.join(combined_transitions)}]\" if len(combined_transitions) > 1 else ''.join(\n",
    "                        combined_transitions)\n",
    "\n",
    "                    afd_df.at[current_state_idx, symbol] = new_value  # Atualiza a transição na tabela AFD\n",
    "\n",
    "                    indeterminisms.setdefault(new_value, set()).update(combined_transitions) # Adiciona os valores ao dicionário de indeterminismos (Ex: {'[AH]': {'A', 'H'}, '[CM]': {'M', 'C'}})\n",
    "\n",
    "                    # Se o novo estado não foi processado, adiciona-o para processamento\n",
    "                    if new_value not in processed_states:\n",
    "                        indices = afd_df.index[afd_df['sigma'] == new_value]\n",
    "                        states_to_process.extend(indices)\n",
    "                        \n",
    "        for new_value, combined_transitions in indeterminisms.items(): \n",
    "            combined_transitions = sorted(combined_transitions)\n",
    "            new_row = pd.Series([new_value] + [''] * (afd_df.shape[1] - 1), index=afd_df.columns)\n",
    "            afd_df = pd.concat([afd_df, new_row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            for state in combined_transitions: \n",
    "                state_row = afnd_df.loc[afnd_df['sigma'] == state].iloc[0]\n",
    "                afd_df.loc[afd_df['sigma'] == new_value, afnd_df.columns[1:]] += state_row[afnd_df.columns[1:]]\n",
    "\n",
    "    return afd_df\n",
    "\n",
    "csv_df = pd.read_csv('./entrada.csv',  header=None)\n",
    "csv_df\n",
    "\n",
    "afnd_df = create_afnd(csv_df)\n",
    "afnd_df\n",
    "\n",
    "afd_df = determinize_afnd(afnd_df)\n",
    "afd_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
