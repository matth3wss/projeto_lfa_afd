{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import OrderedDict as od\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reserved_words_and_counts(csv_df):\n",
    "    \"\"\"\n",
    "    Analyzes a DataFrame containing strings and extracts reserved words, along with their character counts.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_df (pandas.DataFrame): The DataFrame containing strings to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries, each containing information about a reserved word, including the word itself\n",
    "          and its character count. The dictionary format is as follows:\n",
    "          [\n",
    "            {\"word\": str, \"size\": int},\n",
    "            {\"word\": str, \"size\": int},\n",
    "            ...\n",
    "          ]\n",
    "\n",
    "    Note:\n",
    "    - Reserved words are identified as lowercase strings excluding the '<' character.\n",
    "    - The function calculates the size (character count) of each reserved word.\n",
    "    - The returned list contains dictionaries with information about each reserved word and its size.\n",
    "    \"\"\"\n",
    "    reserved_words = [row for row in csv_df.values for char in row if char.islower() and char != \"<\"]         \n",
    "    size = [len(c) for word in reserved_words for c in word]\n",
    "    \n",
    "    json_data = []\n",
    "    for word, size in zip(reserved_words, size):\n",
    "        json = {\n",
    "            \"word\": word,\n",
    "            \"size\": size\n",
    "        }\n",
    "        json_data.append(json)\n",
    "    \n",
    "    return json_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_terminals(csv_df):\n",
    "    \"\"\"\n",
    "    Extracts terminal letters from reserved words obtained by analyzing a DataFrame containing strings.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_df (pandas.DataFrame): The DataFrame containing strings to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of individual terminal letters obtained from the reserved words.\n",
    "\n",
    "    Note:\n",
    "    - This function relies on the 'reserved_words_and_counts' function to identify reserved words and their counts.\n",
    "    - The function extracts individual letters from the reserved words to create a list of terminal letters.\n",
    "    \"\"\"\n",
    "    reserved_words = [row[\"word\"] for row in reserved_words_and_counts(csv_df)]\n",
    "    \n",
    "    terminal_letters = [c for word in reserved_words for char in word for c in char]\n",
    "    return terminal_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_terminal_letters(csv_df):\n",
    "    \"\"\"\n",
    "    Extracts unique terminal letters from a DataFrame containing strings.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_df (pandas.DataFrame): The DataFrame containing strings to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of unique terminal letters found in the strings.\n",
    "\n",
    "    Note:\n",
    "    - The function ignores uppercase letters, 'ε' (epsilon), and non-letter characters.\n",
    "    - Uses the 'collections.OrderedDict' to preserve the order of unique terminal letters.\n",
    "    \"\"\"\n",
    "    terminal_letters = list(od.fromkeys((c for row in csv_df.values for char in row for c in char if c.islower() and c != 'ε')))\n",
    "    return terminal_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_afnd_skeleton(csv_df):\n",
    "    \"\"\"\n",
    "    Creates the skeleton of an AFND (Nondeterministic Finite Automaton) represented as a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_df (pandas.DataFrame): The DataFrame containing strings to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The AFND skeleton represented as a DataFrame with appropriate column headers.\n",
    "\n",
    "    Note:\n",
    "    - The DataFrame includes columns for the alphabet ('sigma') and terminal letters.\n",
    "    - Rows represent states in the AFND.\n",
    "    - The first row is the start state ('S'), and subsequent rows represent states labeled with uppercase letters.\n",
    "    - Empty cells indicate transitions that are not defined.\n",
    "    \"\"\"\n",
    "    terminal_letters = unique_terminal_letters(csv_df)\n",
    "    df = pd.DataFrame(columns=['sigma'] + [str(c) for c in terminal_letters])\n",
    "    df.at[0, 'sigma'] = 'S'\n",
    "    \n",
    "    alphabet = list(string.ascii_uppercase)\n",
    "    size = len(extract_terminals(csv_df))\n",
    "    \n",
    "    symbols = [symbol for letters in alphabet[:size] for symbol in letters]\n",
    "    for i, symbol in enumerate(symbols):\n",
    "        df.at[i+1, \"sigma\"] = symbol\n",
    "    \n",
    "    df = df.fillna('')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_variables(csv_df):\n",
    "    import re\n",
    "    \n",
    "    symbol_pattern = r'<[A-Z]> ::='\n",
    "    variable_pattern = r'([a-z])<([A-Z])>'\n",
    "    \n",
    "    lines = [str(row) for row in csv_df.values if re.search(symbol_pattern, str(row)) for char in row]\n",
    "    \n",
    "    rg = []\n",
    "    \n",
    "    for line in lines:       \n",
    "        symbol = [match[1] for match in re.findall(symbol_pattern, line) if re.search(variable_pattern, line)]\n",
    "        terminals = [match[0] for match in re.findall(variable_pattern, line)]\n",
    "        variables = [match[1] for match in re.findall(variable_pattern, line)]\n",
    "        \n",
    "        json = {\n",
    "            \"symbol\": symbol,\n",
    "            \"terminals\": terminals,\n",
    "            \"variables\": variables\n",
    "        }\n",
    "        rg.append(json)\n",
    "    return rg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_afnd(csv_df):\n",
    "    \"\"\"\n",
    "    Create an afnd from a dataframe\n",
    "    return: afnd\n",
    "    \"\"\"\n",
    "    \n",
    "    afnd_df = create_afnd_skeleton(csv_df) \n",
    "    \n",
    "    reserved_counts = reserved_words_and_counts(csv_df)  \n",
    "    alphabet = list(string.ascii_uppercase)\n",
    "    last_state = 'S'\n",
    "    final_state = []\n",
    "    flag = False\n",
    "    \n",
    "    for row in reserved_counts: \n",
    "        \n",
    "        initial_state = 'S'\n",
    "        \n",
    "        word = [c for char in row[\"word\"] for c in char]\n",
    "        \n",
    "        for index, char in enumerate(word): \n",
    "            if not final_state: # Se estiver vazio\n",
    "                if not flag: \n",
    "                    afnd_df.loc[afnd_df['sigma'] == initial_state, char] = alphabet[index]\n",
    "                    last_state = alphabet[index] \n",
    "                    flag = True\n",
    "                    continue \n",
    "                  \n",
    "                if flag and last_state == alphabet[0]:\n",
    "                    afnd_df.loc[afnd_df['sigma'] == last_state, char] = alphabet[1]   \n",
    "                    last_state = alphabet[1]           \n",
    "            else:      \n",
    "                if last_state[-1] in (final_state):\n",
    "                    if not afnd_df.loc[afnd_df['sigma'] == last_state, char].isna().all():\n",
    "                        afnd_df.loc[afnd_df['sigma'] == initial_state, char] += f\"{',' if afnd_df.loc[afnd_df['sigma'] == initial_state, char].any() else ''}{alphabet[alphabet.index(last_state) + 1]}\"\n",
    "                        last_state = alphabet[((alphabet.index(last_state) + 1))]\n",
    "                    continue\n",
    "                \n",
    "                afnd_df.loc[afnd_df['sigma'] == last_state, char] = alphabet[((alphabet.index(last_state) + 1))]   \n",
    "                last_state = alphabet[((alphabet.index(last_state) + 1))] \n",
    "                      \n",
    "        final_state.append(last_state)\n",
    "        # print(final_state)\n",
    "    return afnd_df\n",
    "\n",
    "csv_df = pd.read_csv('./entrada.csv',  header=None)\n",
    "csv_df\n",
    "\n",
    "afnd_df = create_afnd(csv_df)\n",
    "afnd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sigma</th>\n",
       "      <th>s</th>\n",
       "      <th>e</th>\n",
       "      <th>n</th>\n",
       "      <th>t</th>\n",
       "      <th>a</th>\n",
       "      <th>o</th>\n",
       "      <th>i</th>\n",
       "      <th>u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>[AH]</td>\n",
       "      <td>[CM]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>E</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>G</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>H</td>\n",
       "      <td></td>\n",
       "      <td>I</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>J</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>K</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>K</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>L</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>L</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Q</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Q</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[AH]</td>\n",
       "      <td></td>\n",
       "      <td>BI</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[CM]</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sigma     s     e  n  t  a  o i u\n",
       "0      S  [AH]  [CM]                \n",
       "1      A           B                \n",
       "2      B                            \n",
       "3      C              D             \n",
       "4      D                 E          \n",
       "5      E                    F       \n",
       "6      F                       G    \n",
       "7      G                            \n",
       "8      H           I                \n",
       "9      I              J             \n",
       "10     J                    K       \n",
       "11     K                       L    \n",
       "12     L                            \n",
       "13     M     N                      \n",
       "14     N                 O          \n",
       "15     O                    P       \n",
       "16     P                       Q    \n",
       "17     Q                            \n",
       "18  [AH]          BI                \n",
       "19  [CM]     N        D             "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def determinize_afnd(afnd_df):\n",
    "    afd_df = afnd_df.copy() # Cria uma cópia do DataFrame de AFND\n",
    "    states_to_process = [0] # Inicializa a lista de estados a serem processados\n",
    "    processed_states = set() # Conjunto para manter controle dos estados já processados\n",
    "    indeterminisms = {}\n",
    "    \n",
    "    while states_to_process: # Processa os estados até que a lista esteja vazia\n",
    "        # Pega o próximo estado a ser processado\n",
    "        current_state_idx = states_to_process.pop(0)\n",
    "        current_state = afd_df.iloc[current_state_idx, 0]\n",
    "\n",
    "        if current_state in processed_states: # Verifica se o estado já foi processado\n",
    "            continue\n",
    "\n",
    "        processed_states.add(current_state) # Adiciona o estado atual ao conjunto de estados processados\n",
    "\n",
    "        for symbol in afd_df.columns[1:]: # Itera sobre os símbolos do alfabeto (terminais)\n",
    "            if symbol != 'sigma':\n",
    "                combined_transitions = []\n",
    "\n",
    "                for state in current_state.split(','):\n",
    "                    transitions = afnd_df.loc[afnd_df['sigma'] == state, symbol].values[0]\n",
    "                    combined_transitions.extend(transitions.split(',') if pd.notna(transitions) else [])\n",
    "\n",
    "                if len(combined_transitions) > 1:\n",
    "                    combined_transitions = sorted(combined_transitions)\n",
    "                    new_value = f\"[{''.join(combined_transitions)}]\" if len(combined_transitions) > 1 else ''.join(\n",
    "                        combined_transitions)\n",
    "\n",
    "                    afd_df.at[current_state_idx, symbol] = new_value  # Atualiza a transição na tabela AFD\n",
    "\n",
    "                    indeterminisms.setdefault(new_value, set()).update(combined_transitions) # Adiciona os valores ao dicionário de indeterminismos (Ex: {'[AH]': {'A', 'H'}, '[CM]': {'M', 'C'}})\n",
    "\n",
    "                    # Se o novo estado não foi processado, adiciona-o para processamento\n",
    "                    if new_value not in processed_states:\n",
    "                        indices = afd_df.index[afd_df['sigma'] == new_value]\n",
    "                        states_to_process.extend(indices)\n",
    "                        \n",
    "        for new_value, combined_transitions in indeterminisms.items(): \n",
    "            combined_transitions = sorted(combined_transitions)\n",
    "            new_row = pd.Series([new_value] + [''] * (afd_df.shape[1] - 1), index=afd_df.columns)\n",
    "            afd_df = pd.concat([afd_df, new_row.to_frame().T], ignore_index=True)\n",
    "            \n",
    "            for state in combined_transitions: \n",
    "                state_row = afnd_df.loc[afnd_df['sigma'] == state].iloc[0]\n",
    "                afd_df.loc[afd_df['sigma'] == new_value, afnd_df.columns[1:]] += state_row[afnd_df.columns[1:]]\n",
    "\n",
    "    return afd_df\n",
    "\n",
    "csv_df = pd.read_csv('./entrada.csv',  header=None)\n",
    "csv_df\n",
    "\n",
    "afnd_df = create_afnd(csv_df)\n",
    "afnd_df\n",
    "\n",
    "afd_df = determinize_afnd(afnd_df)\n",
    "afd_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
